{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e640b93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy<2\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/61.0 kB ? eta -:--:--\n",
      "     ------------ ------------------------- 20.5/61.0 kB 165.2 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/61.0 kB 163.8 kB/s eta 0:00:01\n",
      "     ------------------------------- ------ 51.2/61.0 kB 239.5 kB/s eta 0:00:01\n",
      "     -------------------------------------- 61.0/61.0 kB 250.2 kB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/15.8 MB 2.0 MB/s eta 0:00:08\n",
      "    --------------------------------------- 0.3/15.8 MB 3.2 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.7/15.8 MB 4.9 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.2/15.8 MB 7.5 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.4/15.8 MB 5.9 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.9/15.8 MB 7.5 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 2.0/15.8 MB 6.0 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 3.0/15.8 MB 8.2 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 3.0/15.8 MB 8.2 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 3.3/15.8 MB 7.0 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.6/15.8 MB 7.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.6/15.8 MB 6.6 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 4.3/15.8 MB 7.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.9/15.8 MB 7.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.4/15.8 MB 7.6 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 5.6/15.8 MB 7.8 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 6.0/15.8 MB 7.7 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 6.4/15.8 MB 7.7 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 6.6/15.8 MB 7.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 6.7/15.8 MB 7.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 7.0/15.8 MB 7.2 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.6/15.8 MB 7.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 8.0/15.8 MB 7.5 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 8.7/15.8 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 9.0/15.8 MB 7.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.6/15.8 MB 7.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.9/15.8 MB 7.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 10.5/15.8 MB 8.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 10.6/15.8 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 11.3/15.8 MB 8.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.7/15.8 MB 8.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.4/15.8 MB 8.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.1/15.8 MB 8.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.5/15.8 MB 9.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 14.0/15.8 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.8/15.8 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.8 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 8.7 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "Successfully installed numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\user\\AppData\\Local\\Temp\\pip-uninstall-heujv9h2'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\user\\anaconda3\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "streamlit 1.30.0 requires protobuf<5,>=3.20, but you have protobuf 6.33.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install \"numpy<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48e1076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==========================================\n",
    "# 1. LOAD DATA\n",
    "# ==========================================\n",
    "# Ganti dengan nama file Anda, atau buat DataFrame jika data sudah di memory\n",
    "# df = pd.read_csv('data_phishing.csv')\n",
    "\n",
    "# Contoh dummy data agar kode ini bisa langsung di-run (merepresentasikan struktur data Anda)\n",
    "#data = {\n",
    "    'URL': ['google.com', 'bad-site.com', 'secure-bank.com', 'uib.ac.id'], # Ini nanti dibuang\n",
    "    'url_length': [10, 25, 30, 9],\n",
    "    'has_ip_address': [0, 0, 0, 0],\n",
    "    'dot_count': [1, 2, 2, 2],\n",
    "    'https_flag': [1, 0, 1, 1],\n",
    "    'url_entropy': [0.5, 0.9, 0.8, 0.4],\n",
    "    'token_count': [2, 4, 4, 3],\n",
    "    'subdomain_count': [0, 1, 1, 1],\n",
    "    'query_param_count': [0, 2, 1, 0],\n",
    "    'tld_length': [3, 3, 3, 2],\n",
    "    'path_length': [0, 10, 5, 0],\n",
    "    'has_hyphen_in_domain': [0, 1, 1, 0],\n",
    "    'number_of_digits': [0, 0, 0, 0],\n",
    "    'tld_popularity': [1, 0, 1, 0], # Anggap 1 populer\n",
    "    'suspicious_file_extension': [0, 0, 0, 0],\n",
    "    'domain_name_length': [6, 8, 11, 3],\n",
    "    'percentage_numeric_chars': [0.0, 0.0, 0.0, 0.0],\n",
    "    'ClassLabel': [1, 0, 0, 1] # 1: Legitimate, 0: Phishing\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# ==========================================\n",
    "# 2. FEATURE SELECTION (PENTING)\n",
    "# ==========================================\n",
    "# Kita harus memisahkan Fitur (X) dan Target (y)\n",
    "# Drop kolom 'URL' karena string tidak bisa masuk GaussianNB tanpa diubah jadi angka dulu\n",
    "# Drop 'ClassLabel' karena itu adalah kunci jawaban\n",
    "X = df.drop(columns=['URL', 'ClassLabel']) \n",
    "y = df['ClassLabel']\n",
    "\n",
    "# Cek sekilas data yang akan masuk mesin\n",
    "print(\"Fitur yang digunakan:\", list(X.columns))\n",
    "\n",
    "# ==========================================\n",
    "# 3. SPLITTING DATA\n",
    "# ==========================================\n",
    "# Bagi data: 80% untuk latihan, 20% untuk ujian\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ==========================================\n",
    "# 4. TRAINING MODEL (Gaussian Naive Bayes)\n",
    "# ==========================================\n",
    "# Menggunakan Gaussian karena fitur Anda banyak yang bersifat kontinu (length, entropy)\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ==========================================\n",
    "# 5. EVALUASI\n",
    "# ==========================================\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"\\n--- Hasil Evaluasi ---\")\n",
    "print(f\"Akurasi: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
    "print(\"\\nLaporan Klasifikasi:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Phishing (0)', 'Legitimate (1)']))\n",
    "\n",
    "# ==========================================\n",
    "# 6. CONTOH PREDIKSI DATA BARU\n",
    "# ==========================================\n",
    "# Misal ada data URL baru dengan fitur sbb:\n",
    "# url_length=50, has_ip=1, entropy=0.9 (Ciri Phishing kuat)\n",
    "data_baru = [[50, 1, 3, 0, 0.9, 6, 2, 3, 3, 20, 1, 5, 0, 1, 15, 0.1]]\n",
    "\n",
    "# Pastikan urutan kolom data_baru SAMA PERSIS dengan urutan X saat training\n",
    "prediksi_baru = model.predict(data_baru)\n",
    "\n",
    "status = \"Legitimate (Asli)\" if prediksi_baru[0] == 1 else \"Phishing (Palsu)\"\n",
    "print(f\"\\nPrediksi untuk data baru: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4327096c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitur yang digunakan: ['url_length', 'has_ip_address', 'dot_count', 'https_flag', 'url_entropy', 'token_count', 'subdomain_count', 'query_param_count', 'tld_length', 'path_length', 'has_hyphen_in_domain', 'number_of_digits', 'tld_popularity', 'suspicious_file_extension', 'domain_name_length', 'percentage_numeric_chars']\n",
      "\n",
      "--- Hasil Evaluasi ---\n",
      "Akurasi: 95.33%\n",
      "\n",
      "Laporan Klasifikasi:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Phishing (0)       0.97      0.96      0.96     10125\n",
      "Legitimate (1)       0.93      0.95      0.94      6070\n",
      "\n",
      "      accuracy                           0.95     16195\n",
      "     macro avg       0.95      0.95      0.95     16195\n",
      "  weighted avg       0.95      0.95      0.95     16195\n",
      "\n",
      "\n",
      "Prediksi untuk data baru: Legitimate (Asli)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==========================================\n",
    "# 1. LOAD DATA\n",
    "# ==========================================\n",
    "# Ganti dengan nama file Anda, atau buat DataFrame jika data sudah di memory\n",
    "# df = pd.read_csv('data_phishing.csv')\n",
    "\n",
    "df = pd.read_csv('C:/Users/user/Downloads/dsco/train.csv')\n",
    "\n",
    "# ==========================================\n",
    "# 2. FEATURE SELECTION (PENTING)\n",
    "# ==========================================\n",
    "# Kita harus memisahkan Fitur (X) dan Target (y)\n",
    "# Drop kolom 'URL' karena string tidak bisa masuk GaussianNB tanpa diubah jadi angka dulu\n",
    "# Drop 'ClassLabel' karena itu adalah kunci jawaban\n",
    "X = df.drop(columns=['URL', 'ClassLabel']) \n",
    "y = df['ClassLabel']\n",
    "\n",
    "# Cek sekilas data yang akan masuk mesin\n",
    "print(\"Fitur yang digunakan:\", list(X.columns))\n",
    "\n",
    "# ==========================================\n",
    "# 3. SPLITTING DATA\n",
    "# ==========================================\n",
    "# Bagi data: 80% untuk latihan, 20% untuk ujian\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ==========================================\n",
    "# 4. TRAINING MODEL (Gaussian Naive Bayes)\n",
    "# ==========================================\n",
    "# Menggunakan Gaussian karena fitur Anda banyak yang bersifat kontinu (length, entropy)\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ==========================================\n",
    "# 5. EVALUASI\n",
    "# ==========================================\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"\\n--- Hasil Evaluasi ---\")\n",
    "print(f\"Akurasi: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
    "print(\"\\nLaporan Klasifikasi:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Phishing (0)', 'Legitimate (1)']))\n",
    "\n",
    "# ==========================================\n",
    "# 6. CONTOH PREDIKSI DATA BARU\n",
    "# ==========================================\n",
    "# Misal ada data URL baru dengan fitur sbb:\n",
    "# url_length=50, has_ip=1, entropy=0.9 (Ciri Phishing kuat)\n",
    "#data_baru = pd.read_csv(\"C:/Users/user/Downloads/dsco/test - Copy.csv\")\n",
    "\n",
    "# Pastikan urutan kolom data_baru SAMA PERSIS dengan urutan X saat training\n",
    "#prediksi_baru = model.predict(data_baru)\n",
    "\n",
    "#status = \"Legitimate (Asli)\" if prediksi_baru[0] == 1 else \"Phishing (Palsu)\"\n",
    "#print(f\"\\nPrediksi untuk data baru: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b802d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolom Train: ['url_length', 'has_ip_address', 'dot_count', 'https_flag', 'url_entropy', 'token_count', 'subdomain_count', 'query_param_count', 'tld_length', 'path_length', 'has_hyphen_in_domain', 'number_of_digits', 'tld_popularity', 'suspicious_file_extension', 'domain_name_length', 'percentage_numeric_chars']\n",
      "Kolom Test : ['url_length', 'has_ip_address', 'dot_count', 'https_flag', 'url_entropy', 'token_count', 'subdomain_count', 'query_param_count', 'tld_length', 'path_length', 'has_hyphen_in_domain', 'number_of_digits', 'tld_popularity', 'suspicious_file_extension', 'domain_name_length', 'percentage_numeric_chars']\n",
      "\n",
      "Estimasi Akurasi Model: 95.33%\n",
      "Jika akurasi ini bagus, lanjut ke tahap prediksi data test.\n",
      "\n",
      "--- Contoh Hasil Prediksi ---\n",
      "   ID  ClassLabel\n",
      "0   1         1.0\n",
      "1   2         0.0\n",
      "2   3         0.0\n",
      "3   4         1.0\n",
      "4   5         1.0\n",
      "\n",
      "File 'hasil_prediksi_phishing.csv' siap disimpan!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# ==========================================\n",
    "# 1. LOAD DATA TERPISAH\n",
    "# ==========================================\n",
    "# Anggap file Anda bernama 'train.csv' dan 'test.csv'\n",
    "df_train = pd.read_csv('C:/Users/user/Downloads/dsco/train.csv')\n",
    "df_test = pd.read_csv(\"C:/Users/user/Downloads/dsco/test.csv\")\n",
    "# ==========================================\n",
    "# 2. PERSIAPAN FITUR (PREPROCESSING)\n",
    "# ==========================================\n",
    "# A. DATA TRAINING\n",
    "# Pisahkan Fitur (X) dan Target (y)\n",
    "# Pastikan membuang kolom teks mentah 'URL' jika masih ada\n",
    "X_train_full = df_train.drop(columns=['ClassLabel','URL']) # Jika ada kolom 'URL', tambahkan ke list drop\n",
    "y_train_full = df_train['ClassLabel']\n",
    "\n",
    "# B. DATA TESTING\n",
    "# Simpan kolom ID untuk nanti digabungkan di hasil akhir\n",
    "test_ids = df_test['ID']\n",
    "\n",
    "# Buat X_test. PENTING: Kolom harus SAMA PERSIS dengan X_train\n",
    "# Kita buang 'ID' karena itu bukan fitur untuk prediksi phishing\n",
    "X_test_final = df_test.drop(columns=['ID','URL']) # Jika ada kolom 'URL', drop juga di sini\n",
    "\n",
    "# Cek konsistensi kolom (Wajib sama)\n",
    "print(f\"Kolom Train: {X_train_full.columns.tolist()}\")\n",
    "print(f\"Kolom Test : {X_test_final.columns.tolist()}\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. TAHAP VALIDASI INTERNAL (Cek Ombak)\n",
    "# ==========================================\n",
    "# Sebelum memprediksi data test (yang kita tidak tahu jawabannya),\n",
    "# kita \"pura-pura\" uji coba dulu dengan membelah data train.\n",
    "X_lat, X_val, y_lat, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)\n",
    "\n",
    "model_val = GaussianNB()\n",
    "model_val.fit(X_lat, y_lat)\n",
    "val_pred = model_val.predict(X_val)\n",
    "\n",
    "print(f\"\\nEstimasi Akurasi Model: {accuracy_score(y_val, val_pred)*100:.2f}%\")\n",
    "print(\"Jika akurasi ini bagus, lanjut ke tahap prediksi data test.\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. PREDIKSI DATA TESTING SEBENARNYA\n",
    "# ==========================================\n",
    "# Sekarang kita latih ulang model menggunakan 100% data training agar makin pintar\n",
    "final_model = GaussianNB()\n",
    "final_model.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Lakukan prediksi ke data testing (X_test_final)\n",
    "final_predictions = final_model.predict(X_test_final)\n",
    "\n",
    "# ==========================================\n",
    "# 5. SIMPAN HASIL (SUBMISSION)\n",
    "# ==========================================\n",
    "# Gabungkan ID dan Hasil Prediksi menjadi DataFrame baru\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_ids,\n",
    "    'ClassLabel': final_predictions\n",
    "})\n",
    "\n",
    "# Lihat hasilnya\n",
    "print(\"\\n--- Contoh Hasil Prediksi ---\")\n",
    "print(submission.head())\n",
    "\n",
    "# Simpan ke CSV\n",
    "submission.to_csv('hasil_prediksi_phishing.csv', index=False)\n",
    "print(\"\\nFile 'hasil_prediksi_phishing.csv' siap disimpan!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08355033",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
